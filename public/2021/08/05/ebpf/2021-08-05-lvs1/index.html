<!DOCTYPE html>

<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=no">
  
  <title>LVS  学习： 学习和思考 [ Benjmmi 的博客 ]</title>
  
    <!-- stylesheets list from config.yml -->
    
      <link rel="stylesheet" href="/css/iLiKE.css">
    
  
  
<meta name="generator" content="Hexo 8.1.1"></head>
<body>
    <div class="header">
        <div class="container">
    <div class="menu">
      <div class="menu-left">
        <a href="/">
          <img src="/favicon.ico"></img>
        </a>
      </div>
      <div class="menu-right">
        
          
          
          
          
          
          
          <a href="/">首页</a>
        
          
          
          
          
          
          
          <a href="/archives">归档</a>
        
          
          
          
          
          
          
          <a href="/about">关于</a>
        
          
          
          
          
          
          <a target="_blank" rel="noopener" href="https://github.com/Benjmmi">Codes</a>
        
      </div>
    </div>
</div>
    </div>
    <div class="container">
        <h1 class="post-title">LVS  学习： 学习和思考</h1>
<article class="post markdown-style">
  <h1 id="简单认识"><a href="#简单认识" class="headerlink" title="简单认识"></a>简单认识</h1><p>LVS 是 Linux 平台开发的负载均衡器全称 <code>Linux Virtural Server</code> 。负载均衡器的收益主要体现在：</p>
<ol>
<li>提高系统性能</li>
<li>提高系统可扩展性</li>
<li>提高系统的可用性</li>
</ol>
<p>传统上均在均衡器分为三种：</p>
<ol>
<li>DNS 实现负载均衡</li>
<li>硬件实现负载均衡</li>
<li>软件实现负载均衡</li>
</ol>
<h2 id="DNS-负载均衡"><a href="#DNS-负载均衡" class="headerlink" title="DNS 负载均衡"></a>DNS 负载均衡</h2><p>DNS 是最典型的一种方式，基本上大多数的互联网都在用。通过域名解析出 IP，每个 IP 对应不同的服务器实力，这样就完成了琉璃的调度。<br>缺点也很明显：</p>
<ol>
<li>延迟大。主要体现在 TTL 规则与本地缓存时间</li>
<li>调度不均衡。主要体现在 IP 解析策略</li>
<li>调度策略不易扩展。只支持 RR 的方式</li>
<li>后端节点有限制。根据每个公司定制 DNS 策略不一样</li>
</ol>
<h2 id="硬件负载均衡："><a href="#硬件负载均衡：" class="headerlink" title="硬件负载均衡："></a>硬件负载均衡：</h2><p>专门的硬件类似于交换机、路由器。例如 F5 和 A10<br>优点：</p>
<ol>
<li>功能强大。支持各层级负载均衡，更全面的负载均衡算法</li>
<li>新能强大</li>
<li>稳定性高</li>
<li>安全性高<br>缺点：</li>
<li>价格昂贵</li>
<li>扩展性差，无法定制</li>
<li>维护成本高</li>
</ol>
<h2 id="软件负载均衡"><a href="#软件负载均衡" class="headerlink" title="软件负载均衡"></a>软件负载均衡</h2><p>运行在普通服务器上的负载均衡。常见的有 Nginx、HAProxy、LVS。其中的区别：</p>
<ol>
<li>Nginx、HAproxy：七层、四层都支持，需要经过 TCP 协议栈进行判断</li>
<li>LVS：纯四层负载均衡，运行在内核态，通用性高、性能最高<br>优点：</li>
<li>便宜</li>
<li>可扩展</li>
<li>灵活</li>
</ol>
<h2 id="认识-LVS"><a href="#认识-LVS" class="headerlink" title="认识 LVS"></a>认识 LVS</h2><p>LVS 是基于 Linux 内核中的 netfilter 框架实现的负载均衡系统。neifilter 在内核态运行，通过 iptables 工具从用户态控制。</p>
<p><img src="/Benjamin.Yim/assets/images/ebpf/lb003netfilter.png" alt="lb003netfilter.png"></p>
<p>netfilter 共有 5 个 Hook 点：PREROUTING、INPUT、FORWARD、OUTPUT、POSTOUTING</p>
<ul>
<li>PREROUTING：刚进入网络层，还未进行路由查找的包</li>
<li>INPUT：通过路由查找，确定发往本机的包</li>
<li>FORWARD：通过路由查找，要转发的包</li>
<li>OUTPUT：从本机刚进发出的包</li>
<li>POSTOUTING：进入网络层经过路由查找，确定要转发，将要离开本设备的包</li>
</ul>
<p>工作流程：<br>	当一个数据包进入网卡，经过链路层之后进入网络层就会到达 PREROUTING，接着根据目标<br>	IP 地址进行路由查找，如果目标 IP 是本机，数据包继续传递到 INPUT 上，经过协议栈后根据<br>	端口将数据送到相应的应用程序；应用程序处理请求后将响应数据包发送到 OUTPUT 上，最终<br>	通过 POSTROUTING 后发送出网卡。如果目标 IP 不是本机，而且服务器开启了 forward 参<br>	数，就会将数据包递送给 FORWARD 上，最后通过 POSTROUTING 后发送出网卡。</p>
<p>原理如图：</p>
<p><img src="/Benjamin.Yim/assets/images/ebpf/lb004ipvs.png" alt="lb004ipvs.png"></p>
<ul>
<li>当用户访问 <a target="_blank" rel="noopener" href="http://www.sina.com.cn/">www.sina.com.cn</a> 时，用户数据通过层层网络，最后通过交换机进入 LVS 服务器网卡，并进入内核网络层。</li>
<li>进入 PREROUTING 后经过路由查找，确定访问的目的 VIP 是本机 IP 地址，所以数据包进入到 INPUT 链上</li>
<li>IPVS 是工作在 INPUT 链上，会根据访问的 vip+port 判断请求是否 IPVS 服务，如果是则调用注册的 IPVS HOOK 函数，进行 IPVS 相关主流程，强行修改数据包的相关数据，并将数据包发往 POSTROUTING 链上。</li>
<li>POSTROUTING 上收到数据包后，根据目标 IP 地址（后端服务器），通过路由选路，将数据包最终发往后端的服务器上。</li>
</ul>
<h2 id="DR-模式"><a href="#DR-模式" class="headerlink" title="DR 模式"></a>DR 模式</h2><p>问题：当用户访问 <a target="_blank" rel="noopener" href="http://www.sina.com.cn/">www.sina.com.cn</a> 时，用户数据通过层层网络，确定访问的目的 VIP 是本机 IP 地址？<br>VIP 如果不是本机上面，流量包通过广播的方式也不应该进入到 INPUT层，如果启动了 FORWARD 是不是会有转发风暴，在同一个VLAN 里面，会将同一个数据包多次转发到目标主机，是不是浪费了很多宽带<br>答案：通过同程公司的 TVS 系统发现设置范围与自己猜想的类似，如果将四层作为负载均衡器，那么久需要使用到 VIP ，为发散的方式，类似于通过域名解析出真实IP，而 LVS 通过 VIP 解析出真实IP，具体还可以通过 VIP+PORT 映射到具体 IP 。或者以 kubernetes 举例，每个 service 都有自己的 IP，但是每个 service 都没有实体服务，只是起到一个负载均衡的作用，具体服务的还是后面的 POD 实例。<br>那么一个转发机如果有上百万、上千万个服务需要负载均衡这个怎么操控的。难道要绑定上百万个 VIP 在转发机？</p>
<p>问题：DR 模式只是将请求转发到后端，响应不在经过 LVS ，那么是不是可以理解只是在建立连接的时候分配了一个后端实例，建立了长链接，后面的请求就不会在走到 LVS 了。</p>
<p>CIP（客户端真实）+CMAC（中间路由器MAC地址） 					 &#x3D;》 VIP+VMAC  查找 真实服务地址（RMAC）<br>    		  																	    					 ||  转发<br>CIP（客户端真实）+ （VIP&amp;RIP）同网段对应MAC （DMAC）    &#x3D;》 VIP + RMAC<br>																					 				     || 到达真实服务器，请求响应<br>CIP + 	（VIP&amp;RIP）同网段 路由器 MAC    （CMAC）    		       《&#x3D;    VIP + RMAC</p>
<p>解：通过梳理推断，LSV 只会判断 VIP 不会判断目标 MAC，而且整个转发流程 VIP 是透传的所以下次请求还是<br>传送到 LVS 上。其中修改的只有 MAC 地址。路由器也是修改 响应目标真实的 MAC 地址。</p>
<p>缺点：需要后端服务配置，增加了运维难度</p>
<h2 id="NAT-模式"><a href="#NAT-模式" class="headerlink" title="NAT 模式"></a>NAT 模式</h2><p>NAT 模式是很多场景都会使用的模式。比如典型的网络连接就有 NAT 模式。NAT 模式双休流量都经过 LVS ，因此 NAT 模式性能会存在一定的瓶颈。不过与其他模式区别的是，NAT 支持端口映射，且支持 windows 。</p>
<p>CIP（源IP）   				 			&#x3D;》 VIP（目的IP）<br>  VIP+PORT  				  			 ||    查找 RIP，查找成功将目标 VIP 修改为 RIP<br>  CIP（源IP）							&#x3D;》 RIP（目的IP）<br>  												 ||   默认网关配置为 LVS 设备 IP，所以响应到网关 IP，就是 LVS<br>  CIP 									  《&#x3D;   RIP 响应<br>  CIP 不是 LVS 负责的 VIP      ||    查找转发 forward 链<br>  根据目的 IP 和目的 port 查找服务和连接表，将源 IP（RIP）改为 VIP<br>  CIP  									  《&#x3D;   VIP  发出去</p>
<h3 id="优点"><a href="#优点" class="headerlink" title="优点"></a>优点</h3><p>  可以支持 Windows，可以支持端口级别的映射。</p>
<h3 id="缺点"><a href="#缺点" class="headerlink" title="缺点"></a>缺点</h3><p> NAT 模式，进出流量都经过 LVS 负载压力比较大。<br> 如果存在 windows 系统，使用 LVS  必须使用 NAT 模式<br> 存在性能瓶颈</p>
<h2 id="Tunnel-模式"><a href="#Tunnel-模式" class="headerlink" title="Tunnel 模式"></a>Tunnel 模式</h2><p> Tunnel 与 DR 模式一样，也是属于一种单臂模式，只有请求会经过 LVS ，响应数据直接返回给客户端，支持夸机房操作。</p>
<p> CIP（源IP）   							&#x3D;》  VIP（目的IP）<br> 												    ||     查找IP路由，确定是本机IP，转发到 LVS ，<br> 												    ||    通过目的 IP+ PORT 查找 RIP<br>CIP 												&#x3D;》 dev tunnel<br>													||  DIP&#x3D;CIP    RIP&#x3D;目的IP  添加到 IP 头部前面，将数据包转发到 output 上<br>CIP（DIP+RIP）LVS                  &#x3D;》    后端服务器<br>目标服务器卸载 tunnel 头部模块，获取 CIP  和  VIP ，<br>													||  判断 tunl0 配置的 IP &#x3D;&#x3D; vip<br>													&#x3D;》 转发到应用程序<br>														<br>CIP：Client IP，表示的是客户端 IP 地址。<br>VIP：Virtual IP，表示负载均衡对外提供访问的 IP 地址，一般负载均衡 IP 都会通过 Virtual IP 实现高可用。<br>RIP：RealServer IP，表示负载均衡后端的真实服务器 IP 地址。<br>DIP：Director IP，表示负载均衡与后端服务器通信的 IP 地址。<br>CMAC：客户端的 MAC 地址，准确的应该是 LVS 连接的路由器的 MAC 地址。<br>VMAC：负载均衡 LVS 的 VIP 对应的 MAC 地址。<br>DMAC：负载均衡 LVS 的 DIP 对应的 MAC 地址。<br>RMAC：后端真实服务器的 RIP 地址对应的 MAC 地址。 </p>
<p>  10.0.2.15<br>					<br>192.168.33.11<br>192.168.33.8<br>192.168.33.10</p>
<p>vip&#x3D;192.168.33.12<br>rs1&#x3D;192.168.33.11<br>rs2&#x3D;192.168.33.13<br>&#x2F;sbin&#x2F;ipvsadm -C<br>&#x2F;sbin&#x2F;ipvsadm -A -t $vip:8088 -s rr<br>&#x2F;sbin&#x2F;ipvsadm -a -t $vip:8088 -r $rs1:8088 -g<br>&#x2F;sbin&#x2F;ipvsadm -a -t $vip:8088 -r $rs2:8088 -g</p>
<p>sudo ifconfig lo:0 192.168.33.12 netmask 255.255.255.0 broadcast 192.168.33.255<br>sudo route add -host 192.168.33.12 dev eth1:0</p>
<p>网络发展方向：<br>熟悉高性能服务器，负载均衡，网关及代理 LVS，Nginx、Haproxy，Envoy等<br>熟悉SDN，云原生网络系统、VPC，有DPDK开发经验<br>精通网络虚拟化技术 , Overlay的设计与实现<br>NOS、Openflow、DPDK&#x2F;VPP、P4lang、LVS、K8S<br>可编程智能网卡（FPGA、NP、SoC）<br>QUIC、GOLANG</p>
<p>export HTTP_PROXY&#x3D;<a target="_blank" rel="noopener" href="http://192.168.0.177:58591/">http://192.168.0.177:58591</a>; export HTTPS_PROXY&#x3D;<a target="_blank" rel="noopener" href="http://192.168.0.177:58591/">http://192.168.0.177:58591</a>; export ALL_PROXY&#x3D;socks5:&#x2F;&#x2F;192.168.0.177:51837</p>
<h1 id="参考文档"><a href="#参考文档" class="headerlink" title="参考文档"></a>参考文档</h1><p><a target="_blank" rel="noopener" href="https://www.linuxblogs.cn/articles/20010215.html">负载均衡 LVS 入门教程详解</a><br><a target="_blank" rel="noopener" href="https://www.linuxblogs.cn/articles/20010419.html">负载均衡 LVS 入门教程详解</a><br><a target="_blank" rel="noopener" href="http://www.linuxvirtualserver.org/zh/lvs1.html">章文嵩 的博客</a></p>

</article>

    <div class="pagenator post-pagenator">
    
    
        <a class="extend prev post-prev" href="../../../10/ebpf/2021-08-10-lvs_read_source/">上一篇</a>
    

    
    <p>上次更新 2024-08-26</p>
    
    
        <a class="extend next post-next" href="../2021-08-05-lvs2/">下一篇</a>
    
    </div>


    </div>
    <div class="footer">
        <div class="container">
    <div class="social">
	<ul class="social-list">
		
			
				
				
				<li>
					<a href="mailto:2228598786@qq.com" title="email" target="_blank">
					<i class="fa fa-email"></i>
					</a>
				</li>
			
		
			
		
			
		
			
		
			
		
			
		
			
				
				<li>
					<a href="https://github.com/Benjmmi" title="github" target="_self">
					<i class="fa fa-github"></i>
					</a>
				</li>
			
		
			
		
			
		
			
		
			
		
			
		
			
		
	</ul>
</div>
    <div class="copyright">
        <span>
            
            
            
                © Benjmmi 2017 - 2025
            
        </span>
    </div>
    <div class="power">
        <span>
            Powered by <a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a> & <a target="_blank" rel="noopener" href="https://github.com/CaiChenghan/iLiKE">iLiKE Theme</a>
        </span>
    </div>
    <script src="https://cdn.bootcss.com/jquery/3.3.1/jquery.js"></script>
    <!--page counter part-->
<script>
function addCount (Counter) {
    url=$('.article-date').attr('href').trim();
    title = $('.article-title').text().trim();
    var query = new AV.Query(Counter);
    //use url as unique idnetfication
    query.equalTo("url",url);
    query.find({
        success: function(results) {
            if (results.length>0) {
                var counter=results[0];
                counter.fetchWhenSave(true); //get recent result
                counter.increment("time");
                counter.save();
            } else {
                var newcounter=new Counter();
                newcounter.set("title",title);
                newcounter.set("url",url);
                newcounter.set("time",1);
                newcounter.save(null,{
                    success: function(newcounter) {
                        //alert('New object created');
                    }, error: function(newcounter,error) {
                        alert('Failed to create');
                    }
                })
            }
        },
        error: function(error) {
            //find null is not a error
            alert('Error:'+error.code+" "+error.message);
        }
    });
}
$(function() {
    var Counter=AV.Object.extend("Counter");
    //only increse visit counting when intering a page
    if ($('.article-title').length == 1) {
       addCount(Counter);
    }
    var query=new AV.Query(Counter);
    query.descending("time");
    // the sum of popular posts
    query.limit(10); 
    query.find({
        success: function(results) {
                for(var i=0;i<results.length;i++) {
                    var counter=results[i];
                    title=counter.get("title");
                    url=counter.get("url");
                    time=counter.get("time");
                    // add to the popularlist widget
                    showcontent=title+" ("+time+")";
                    //notice the "" in href
                    $('.popularlist').append('<li><a href="'+url+'">'+showcontent+'</a></li>');
                }
            },
        error: function(error) {
            alert("Error:"+error.code+" "+error.message);
        }
    });
});
</script>
</div>

  <script src='https://unpkg.com/mermaid@11.12.1/dist/mermaid.min.js'></script>
  <script>
    if (window.mermaid) {
      mermaid.initialize({theme: 'forest'});
    }
  </script>
    </div>
</body>
</html>
