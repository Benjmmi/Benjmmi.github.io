<!DOCTYPE html>

<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=no">
  
  <title>flink_cdc_概念拆解 [ Benjmmi 的博客 ]</title>
  
    <!-- stylesheets list from config.yml -->
    
      <link rel="stylesheet" href="/css/iLiKE.css">
    
  
  
<meta name="generator" content="Hexo 8.1.1"></head>
<body>
    <div class="header">
        <div class="container">
    <div class="menu">
      <div class="menu-left">
        <a href="/">
          <img src="/favicon.ico"></img>
        </a>
      </div>
      <div class="menu-right">
        
          
          
          
          
          
          
          <a href="/">首页</a>
        
          
          
          
          
          
          
          <a href="/archives">归档</a>
        
          
          
          
          
          
          
          <a href="/about">关于</a>
        
          
          
          
          
          
          <a target="_blank" rel="noopener" href="https://github.com/Benjmmi">Codes</a>
        
      </div>
    </div>
</div>
    </div>
    <div class="container">
        <h1 class="post-title">flink_cdc_概念拆解</h1>
<article class="post markdown-style">
  <blockquote>
</blockquote>
<h1 id="动机"><a href="#动机" class="headerlink" title="动机"></a>动机</h1><p>对目前所做工作的进一步演化，行业内知识对标</p>
<h1 id="Flink-CDC-概述"><a href="#Flink-CDC-概述" class="headerlink" title="Flink CDC 概述"></a>Flink CDC 概述</h1><p>Flink CDC 是基于数据库日志 CDC（Change Data Capture）技术的实时数据集成框架，支持了全增量一体化、无锁读取、并行读取、表结构变更自动同步、分布式架构等高级特性。</p>
<h1 id="Flink-CDC-3-0-设计动机"><a href="#Flink-CDC-3-0-设计动机" class="headerlink" title="Flink CDC 3.0 设计动机"></a>Flink CDC 3.0 设计动机</h1><p>之前使用 Flink CDC 2.x 调整表结构过程涉及到多个系统组件的手动执行：</p>
<ul>
<li><p>暂停作业</p>
</li>
<li><p>记录 savepoint</p>
</li>
<li><p>同步更新上下游数据库 Schema</p>
</li>
<li><p>最后从保存点恢复作业。<br>这一过程不仅引入了数据同步的延迟，还存在因 Schema 不同步导致的作业稳定性风险，而这些问题超出了 Flink CDC 作为单一 Source connector 所能解决的能力范畴。</p>
</li>
<li><p>历史数据规模大：数据库的历史数据规模大，100T+ 规模很常见</p>
</li>
<li><p>增量数据实时性要求高：数据库的增量数据业务价值高，且价值随时间递减，需要实时处理</p>
</li>
<li><p>数据的保序性：CDC 数据的加工结果通常需要强一致性语义，需要处理工具支持全局保序</p>
</li>
<li><p>表结构动态变化：增量数据随时间增长，数据对应的表结构会不断演进</p>
</li>
</ul>
<p>历史问题：</p>
<ol>
<li>使用复杂<ul>
<li>只是一组 Flink Source Connector</li>
<li>不提供端到端数据集成</li>
<li>使用需要编写 SQL&#x2F;Java 代码</li>
</ul>
</li>
<li>可扩展性不足<ul>
<li>不支持自定义数据结构写入拓扑</li>
<li>不支持全量和增量阶段的扩缩容</li>
<li>自资源消耗大</li>
</ul>
</li>
<li>不支持结构变更<ul>
<li>表结构变更同步不支持</li>
<li>无法捕获上游的 Schema 变更</li>
<li>需要重新编写作业来维护表结构</li>
</ul>
</li>
</ol>
<p>目标：</p>
<ol>
<li>易用性<ul>
<li>新增 <code>YAML</code> 定义数据同步作业</li>
<li>面向数据集成用户的新<code>API</code></li>
<li>原油 <code>API</code> 使用维护，用于高级使用</li>
</ul>
</li>
<li>扩展性<ul>
<li>支持自定义数据路由规则</li>
<li>数据 Sink 支持同时写入多张表</li>
<li>支持资源灵活调度回收</li>
</ul>
</li>
<li>灵活性<ul>
<li>支持自动捕获上游 <code>Schema</code> 变更</li>
<li>支持应用 <code>Schema</code> 变更到下游</li>
<li>支持动态增加&#x2F;删除捕获表</li>
</ul>
</li>
</ol>
<p>概括为</p>
<ul>
<li>端到端：端到端数据集成，用户只需要配置一个 YAML 文件就能快速构建数据入湖入仓作业，帮助用户轻松构建同步作业</li>
<li>自动化：完整的数据同步，上游 <code>Schema</code> 变更自动同步到下游，已有作业支持动态加表</li>
<li>极致扩展：空闲资源自动回收，一个 <code>Sink</code> 实例支持写入多表,占用数据库连接少，增量读取阶段自动关闭空闲读取器，节省计算资源</li>
</ul>
<h1 id="架构"><a href="#架构" class="headerlink" title="架构"></a>架构</h1><p><img src="https://static001.geekbang.org/infoq/03/030e8f8e9cdc789dda5846819b27317e.webp?x-oss-process=image/resize,p_80/format,png" alt="image"></p>
<p>Flink CDC 3.0 的整体架构自顶而下分为 4 层：</p>
<ul>
<li><strong>Flink CDC AP</strong>I：面向终端用户的 API 层，用户使用 YAML 格式配置数据同步流水线，使用 Flink CDC CLI 提交任务</li>
<li><strong>Flink CDC Connect</strong>：对接外部系统的连接器层，通过对 Flink 与现有 Flink CDC source 进行封装实现对外部系统同步数据的读取和写入</li>
<li><strong>Flink CDC Composer</strong>：同步任务的构建层,创建 Flink CDC 作业执行算子图、生成 Flink 任务，将用户的同步任务翻译为 Flink DataStream 作业.</li>
<li><strong>Flink CDC Runtime</strong>：运行时层，根据数据同步场景高度定制 Flink 算子，实现 <code>Schema Evolution</code>、<code>Transform</code>、<code>Route</code>等高级功能</li>
</ul>
<p>分别对应项目 </p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">/fink-cdc</span><br><span class="line">---/flink-cdc-cli</span><br><span class="line">---/flink-cdc-composer</span><br><span class="line">---/flink-cdc-connect</span><br><span class="line">---/flink-cdc-runtime</span><br></pre></td></tr></table></figure>
<p>此外Flink CDC 3.0 采用了<strong>无状态（stateless）<strong>的设计模式，不承担持久化任何额外状态的职责，保持了架构的简洁性与轻量化；诸如初始化、执行与终止等关键功能均由 Flink 原生引擎框架</strong>承担</strong>，且能够更好地利用 Flink 成熟且强大的<strong>作业管理</strong>与<strong>调度机制</strong>。</p>
<h1 id="逐层拆解"><a href="#逐层拆解" class="headerlink" title="逐层拆解"></a>逐层拆解</h1><h2 id="API-层"><a href="#API-层" class="headerlink" title="API 层"></a>API 层</h2><p>Flink CDC 3.0 的用户 API 设计专注于数据集成场景，用户无需关注框架实现，只需使用 YAML 格式描述数据来源与目标端即可快速构建一个数据同步任务。</p>
<p>总共分为五大模块：<br>    - 源数据库配置<br>    - 目标数据库设定<br>    - 数据转换与过滤逻辑<br>    - 数据路由策略<br>    - 全局作业选项所需的信息</p>
<p><img src="https://static001.geekbang.org/infoq/7c/7cf23b6cdcf2f464f3873d779268cda2.webp?x-oss-process=image/resize,p_80/format,png" alt="image"></p>
<h2 id="Connect-连接层"><a href="#Connect-连接层" class="headerlink" title="Connect 连接层"></a>Connect 连接层</h2><ol>
<li>为了更好地将外部系统对接至 Flink CDC 3.0 的数据同步流水线， 定义了 <code>Pipeline Connector</code> API<ul>
<li><strong>DataSource</strong>：Flink CDC 3.0 的数据源，由负责构建 Flink Source 的 <code>EventSourceProvider</code> 和提供元信息读取能力的 <code>MetadataAccessor</code>组成。DataSource 从外部系统中读取变更<code>事件 Event</code>，并传递给下游算子。</li>
<li><strong>DataSink</strong>：Flink CDC 3.0 的数据目标端，由负责构建 Flink Sink 的 <code>EventSinkProvider</code> 和提供对目标端元信息修改能力的 <code>MetadataApplier</code> 构成。DataSink 将上游算子传递来的变更事件 <code>Event</code> 写出至外部系统，<code>MetadataApplier</code> 负责处理上游的 <code>schema</code> 变更信息并应用至外部系统，实现 schema 变更的实时处理。</li>
</ul>
</li>
</ol>
<p><img src="https://static001.geekbang.org/infoq/91/91b66ea39acb5fd4c14d9aefa7fbf9af.webp?x-oss-process=image/resize,p_80/format,png" alt="image"></p>
<ol start="2">
<li><code>Schema</code> 变更处理是上游数据库中十分常见的用户场景，也是数据同步框架实现的难点。针对该场景，Flink CDC 3.0 在作业拓扑中引入了 <code>SchemaRegistry</code>，结合 <code>SchemaOperator</code> 协调并控制作业拓扑中的 <code>schema</code> 变更事件处理。当上游数据源发生 <code>schema</code> 变更时，SchemaRegistry 会控制 <code>SchemaOperator</code> 以暂停数据流，并将流水线中的数据从 sink 全部刷出以保证 <code>schema</code> 一致性。当 <code>schema</code> 变更事件在外部系统处理成功后，<code>SchemaOperator</code> 恢复数据流，完成本次 <code>schema</code> 变更的处理。</li>
</ol>
<p><img src="https://ucc.alicdn.com/gfbp4bwpctdbo_20231219_0c124ba82fae4da4a6e84aa6dc98ea3b.png?x-oss-process=image/resize,w_1400/format,webp" alt="image"></p>
<h3 id="逐步拆解-Schema-变更处理"><a href="#逐步拆解-Schema-变更处理" class="headerlink" title="逐步拆解 Schema 变更处理"></a>逐步拆解 <code>Schema</code> 变更处理</h3><p> <code>Schema</code> 变更处理过程：</p>
<ol>
<li><p>在作业的某一个 <code>Schema Operator</code> 节点收到表结构变更事件时</p>
</li>
<li><p><code>Schema Operator</code> 会立即阻塞来自上游的所有事件（包括数据变更事件和表结构变更事件）</p>
</li>
<li><p>并且向 <code>Schema</code> 注册表中心 Registry 报告；<br><img src="https://static001.geekbang.org/infoq/be/be6617d3939734b3e4b13c452e119fd5.webp?x-oss-process=image/resize,p_80/format,png" alt="image"></p>
</li>
<li><p>注册表中心在收到表结构变更请求后，会先向下游发送 <code>FlushEvent</code>，要求 <code>Sink</code> 将未提交的数据变更全部落盘；因为按照语义，必须在所有先前的、对应旧 <code>Schema</code> 信息的数据记录都正确落盘之后，方可开始应用一次结构变更。<br><img src="https://static001.geekbang.org/infoq/b8/b891577411aad6e35f036b154c874eec.webp?x-oss-process=image/resize,p_80/format,png" alt="image"></p>
</li>
<li><p>在所有的 <code>Sink</code> 都完成 <code>Flush</code> 操作并通报 <code>Registry</code> 后，</p>
</li>
<li><p><code>Registry</code> 会通过<code> MetadataApplier API</code> 将表结构变更应用到下游数据库之中；<br><img src="https://static001.geekbang.org/infoq/3a/3a620d80f84e3e374207da03670a8ddd.webp?x-oss-process=image/resize,p_80/format,png" alt="image"></p>
</li>
<li><p>最后，向 Schema Operator 告知此次 Schema 变更事件结束 ~~不需要确定是否变更成功吗？～～</p>
</li>
<li><p>可以停止阻塞，开始继续处理来自上游的其他事件了。</p>
</li>
</ol>
<p>而在向下游应用表结构变更发生错误时，Flink CDC 提供了多种可配置的行为模式：</p>
<ul>
<li><strong>Ignore</strong> 模式下，忽略所有结构变更。(非常宽松)</li>
<li><strong>Try Evolve</strong> 模式下，尝试进行结构变更，失败则忽略。（较为宽松）</li>
<li><strong>Evolve</strong>（默认）模式下，进行结构变更，失败则终止任务。（严格）</li>
<li><strong>Exception</strong> 模式下，拒绝任何结构变更，一旦发生直接终止任务。（非常严格）</li>
</ul>
<p><img src="https://static001.geekbang.org/infoq/e2/e2f80108e75148501789b95f22c47480.webp?x-oss-process=image/resize,p_80/format,png" alt="image"></p>
<p>从 Ignore 到 Exception，对 Schema Evolution 的限制是从最宽容到最严格的。通过支持不同的配置文件模式配置，用户可以根据自己的需要和实际需求，为每个作业配置特定的 Schema Evolution 规则。</p>
<p><img src="https://static001.geekbang.org/infoq/8b/8bd98e87368b7013484f6c28d93ace9a.webp?x-oss-process=image/resize,p_80/format,png" alt="image"></p>
<h2 id="数据转换与过滤逻辑"><a href="#数据转换与过滤逻辑" class="headerlink" title="数据转换与过滤逻辑"></a>数据转换与过滤逻辑</h2><p>Flink CDC 3.0 通过引入强大的数据转换（Transform）支持，在确保配置简洁直观的同时，提供了丰富的数据处理和转换的能力。在 SQL 语句中编写的 SELECT、WHERE 等指令，或是 Java 代码里调用的 .map、.filter等算子表达式实现的转换逻辑，现在仅需 YAML 配置文件中撰写简洁的语句即可清楚地定义。（这里设计需要改进，projection 应该用数组）<br><img src="https://static001.geekbang.org/infoq/bf/bfb4859bf477aac3361df111c9694fd3.webp?x-oss-process=image/resize,p_80/format,png" alt="image"></p>
<h2 id="Route-路由设计"><a href="#Route-路由设计" class="headerlink" title="Route 路由设计"></a>Route 路由设计</h2><p>在数据同步中，一个常见的使用场景是将上游由于业务或数据库性能问题而拆分的多表在下游系统合并为一张表。Flink CDC 3.0 使用路由（<code>Route</code>）机制实现分库分表合并的能力。用户可以在配置文件中定义 <code>Route</code> 规则使用正则表达式匹配多张上游表，并将其指向同一张目标表，实现分库分表数据的归并。</p>
<p><img src="https://ucc.alicdn.com/gfbp4bwpctdbo_20231219_f94f3898baba442da66f2947db67727a.png?x-oss-process=image/resize,w_1400/format,webp" alt="image"></p>
<p>路由功能也可以与表结构变更功能共同发挥作用，提供额外的容错功能。例如，在上游某一张分表发生表结构变更，导致上游合并的三张分表结构产生差异的时候，一般的处理行为就是认为合并分表的条件已经不再满足了，直接抛出失败停止作业。CDC 为了尽量保证作业的<strong>容错性</strong>、能够在保证不丢失有效数据的情况下尽量稳定地持续运行作业，提供了额外的<code>***容错机制选项***</code>，允许 <code>Pipeline</code> 作业在某些情况下容忍错误继续运行。<br>例如，在上游某一张表增加了额外的一列的时候，这一信息会被自动同步到下游；而对于其他不存在这一新增列的表，对应的数据行则会自动被用 NULL 值填充，以便符合下游最新的结构。类似的，删除某一张表的一列也不会导致下游表的对应列被删除，只是这张表接下来到来的数据会被填充上空值。对于列类型修改导致各张分表对应字段类型不一致的情况，则会尝试推导出能够无损容纳所有上游类型的协变类型。例如，框架允许将 <code>FLOAT</code> 宽转换为 <code>DOUBLE</code>，<code>SMALLINT</code> 转换 <code>BIGINT</code>、精度较低的 <code>DECIMAL</code> 转换到精度较高的数字类型。<br>但在这种无损的转换不成立的时候，CDC 还是会抛出错误并停止作业，而不是默默地进行有损的数据压缩和变换。作为一个数据集成框架，在进行隐式自动转换的时候，遵守的设计原则是不丢弃、不删除、不压缩任何来自上游的数据，确保在默认的模式下尽可能完整地将数据传递给下游。</p>
<h1 id="核心实现"><a href="#核心实现" class="headerlink" title="核心实现"></a>核心实现</h1><p><code>Event</code> 是 Flink CDC 3.0 内部进行数据处理及传输的数据结构接口，其作用类似于 Flink SQL 中的 <code>RowData</code> 接口。<code>Event</code> 目前所有的实现如下图所示。</p>
<pre class="mermaid">graph TB
    A(AddColumnEvent) --> B[SchemaChangeEvent]
    C(AlterColumnTypeEvent) --> B[SchemaChangeEvent]
    D(CreateTableEvent) --> B[SchemaChangeEvent]
    E(DropColumnEvent) --> B[SchemaChangeEvent]
    F(RenameColumnEvent) --> B[SchemaChangeEvent]
    G(DataChangeEvent) --> H[ChangeEvent]
    B(SchemaChangeEvent) --> H[ChangeEvent]
    H(ChangeEvent) --> J[Event]
    K(FlushEvent) --> J[Event]</pre>

<h2 id="ChangeEvent"><a href="#ChangeEvent" class="headerlink" title="ChangeEvent"></a>ChangeEvent</h2><p><code>ChangeEvent</code> 接口代表着在一张表上发生过的变更事件，实现类包括数据变更事件和表结构变更事件<br><code>DataChangeEvent</code> 里保存了完整的数据变更信息，即包含:</p>
<ol>
<li>变更前（<code>before</code>）每条记录的字段值</li>
<li>变更后（<code>after</code>）每条记录的字段值</li>
</ol>
<p>SchemaChangeEvent里面保存了表结构变更：</p>
<ol>
<li>增加列</li>
<li>删除列</li>
<li>修改列类型</li>
<li>重命名列明</li>
<li>创建表</li>
</ol>
<h2 id="FlushEvent"><a href="#FlushEvent" class="headerlink" title="FlushEvent"></a>FlushEvent</h2><p><code>FlushEvent</code> 是包含数据刷写控制逻辑的特殊事件。当发生表结构变更事件后，之前的数据可能尚未处理完，链路上会并存两种不同表结构的数据。大部分数据库不允许直接在同一批次中混合处理两种表格式的数据，在处理新版本的数据之前，必须确保旧版本的数据已全部完成刷写操作。<code>FlushEvent</code> 作用是间隔这两种数据，在 <code>Sink</code> 端接受到 <code>FlushEvent</code> 后，就需要将之前缓存的数据全部刷写出去。</p>
<h1 id="算子编排"><a href="#算子编排" class="headerlink" title="算子编排"></a>算子编排</h1><p><code>Flink CDC</code> 根据数据集成的场景，深度定制了 Flink DataStream 的算子链路，目前制定的数据处理链路如下图所示：</p>
<pre class="mermaid">graph LR
Source-->Transform-->Schema-->Route-->Partition-->Sink</pre>
<h2 id="Source"><a href="#Source" class="headerlink" title="Source"></a>Source</h2><p><code>Source</code> 模块负责生产在链路中流转的变更事件。<code>Flink CDC</code> 2.0 提供了强大的全增量同步、并发读取的能力，已经能够生成包含各类变更事件信息的 <code>SourceRecord</code> 对象，在此基础上，只需要再实现一个将 <code>SourceRecord</code> 解析成前面介绍的各种表变更事件的 <code>DebeziumDeserializationSchema</code> 自定义转换器，就能完成 <code>Flink CDC</code> 3.0 数据源的接入。</p>
<p>在第一次启动时，<code>Source</code> 模块需要<strong>先拉取表结构</strong>信息，并生成 <code>CreateTableEvent</code> 发送到下游中，这是为了让下游节点能够解析 <code>DataChangeEvent</code>。</p>
<p>在 <code>Flink CDC</code> 里，添加了丰富的 <code>DDL</code> 解析器来<strong>辅助数据库变更事件</strong>生成。具体来说，通过在 <code>Alter</code> 语句的解析树中每个规则（诸如语句、表达式和字面量等）的**进入（Enter）<strong>和</strong>退出（Exit）**阶段添加自定义逻辑，能够生成我们需要的各种 <code>SchemaChangeEvent</code>。以删除列的生成逻辑为例，在 <code>CustomAlterTableParserListener</code> 类的 <code>enterAlterByDropColumn</code> 方法中获取到被删除的列的列名，可以据此生成一个 <code>DropColumnEvent</code> 事件。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">enterAlterByDropColumn</span><span class="params">(MySqlParser.AlterByDropColumnContext ctx)</span> &#123;</span><br><span class="line">    <span class="type">String</span> <span class="variable">removedColName</span> <span class="operator">=</span> parser.parseName(ctx.uid());</span><br><span class="line">    changes.add(<span class="keyword">new</span> <span class="title class_">DropColumnEvent</span>(currentTable, Collections.singletonList(removedColName)));</span><br><span class="line">    <span class="built_in">super</span>.enterAlterByDropColumn(ctx);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="Schema"><a href="#Schema" class="headerlink" title="Schema"></a>Schema</h2><p>在发生表结构变更事件以后，<code>Schema</code> 模块负责阻塞上游数据的继续发放，直到旧版本格式数据刷写完毕。这个逻辑需要通过 <code>FlushEvent</code> 来传递，由于下游可能存在多个 <code>Sink</code>，需要通过运行在 <code>JobManager</code> 上的一个 <code>OperatorCoordinator</code> 来进行管控，这个 <code>OperatorCoordinator</code> 称为 <code>SchemaRegistry</code>。</p>
<p>具体来说，处理表结构变更的流程如下图所示：</p>
<pre class="mermaid">sequenceDiagram
	participant A as Source
    participant B as SchemaOperator
    participant C as SchemaRegister
    participant D as DataSinkWriterOperator
	participant E as ExternalSystem
    D->>C: 1. register writer
    loop
        A->>+ B: 2. SchemaChangeEvent
        B->>+C: 2. SchemaChangeRequest
        C->>+C: 2. cache SchemaChangeEvent
        C-->>-B: SchemaChangeResponse
        B->>+D: 3. FlushEvent
        D->>+E: 3. flush DataChangeEvent
        D-->>-C: 3. FlushSuceessEvent
        B->>+D: 4. SchemaChangeEvent
        B->>+C: 5. ReleaseUpstreamRequest
        C->>+E: 6. apply SchemaChangeEvent
        C-->>-B: 6. ReleaseUpstreamResponse
    end</pre>

<h2 id="Route"><a href="#Route" class="headerlink" title="Route"></a>Route</h2><p>Route 模块提供了表名映射的能力。通过为每一个源表中的数据设置其写入的目标表，通过一对一以及多对一的映射配置，我们能够实现整库同步和简单的分库分表同步功能。</p>
<p>Route 模块基于 Flink 的 RichMapFunction 实现，允许通过 source-table 指定一个正则表达式规则，将一系列符合正则表达式规则的表名，替换到另外一个由 sink-table 指定的表名。RouteFunction 的核心代码如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> Event <span class="title function_">map</span><span class="params">(Event event)</span> <span class="keyword">throws</span> Exception &#123;</span><br><span class="line">    <span class="type">ChangeEvent</span> <span class="variable">changeEvent</span> <span class="operator">=</span> (ChangeEvent) event;</span><br><span class="line">    <span class="type">TableId</span> <span class="variable">tableId</span> <span class="operator">=</span> changeEvent.tableId();</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> (Tuple2&lt;Selectors, TableId&gt; route : routes) &#123;</span><br><span class="line">        <span class="type">Selectors</span> <span class="variable">selectors</span> <span class="operator">=</span> route.f0;</span><br><span class="line">        <span class="type">TableId</span> <span class="variable">replaceBy</span> <span class="operator">=</span> route.f1;</span><br><span class="line">        <span class="keyword">if</span> (selectors.isMatch(tableId)) &#123;</span><br><span class="line">            <span class="keyword">return</span> recreateChangeEvent(changeEvent, replaceBy);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> event;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="Partition"><a href="#Partition" class="headerlink" title="Partition"></a>Partition</h2><p>在数据同步场景，数据的生产和消费的速率常常是不匹配的，用户希望能够通过增加 Sink 的并发度来提高数据处理的速率。Partition 模块负责分发事件到不同的 Sink 中。<br>在 Partition 阶段，数据变更事件按照表名和主键作为哈希键，保证同一张表中相同主键的数据不会因数据分发出现乱序的情况。哈希键的计算方式如下所示：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> Integer <span class="title function_">apply</span><span class="params">(DataChangeEvent event)</span> &#123;</span><br><span class="line">    List&lt;Object&gt; objectsToHash = <span class="keyword">new</span> <span class="title class_">ArrayList</span>&lt;&gt;();</span><br><span class="line">    <span class="comment">// Table ID</span></span><br><span class="line">    <span class="type">TableId</span> <span class="variable">tableId</span> <span class="operator">=</span> event.tableId();</span><br><span class="line">    Optional.ofNullable(tableId.getNamespace()).ifPresent(objectsToHash::add);</span><br><span class="line">    Optional.ofNullable(tableId.getSchemaName()).ifPresent(objectsToHash::add);</span><br><span class="line">    objectsToHash.add(tableId.getTableName());</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Primary key</span></span><br><span class="line">    <span class="type">RecordData</span> <span class="variable">data</span> <span class="operator">=</span></span><br><span class="line">            event.op().equals(OperationType.DELETE) ? event.before() : event.after();</span><br><span class="line">    <span class="keyword">for</span> (RecordData.FieldGetter primaryKeyGetter : primaryKeyGetters) &#123;</span><br><span class="line">        objectsToHash.add(primaryKeyGetter.getFieldOrNull(data));</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Calculate hash</span></span><br><span class="line">    <span class="keyword">return</span> (Objects.hash(objectsToHash.toArray()) * <span class="number">31</span>) &amp; <span class="number">0x7FFFFFFF</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>同时由于 Sink 模块需要维护表结构信息，对于表结构变更事件，需要广播到每一个并发里。对于控制数据刷写的 FlushEvent，也需要广播到每一个下游的每一个通道里。</p>
<p><img src="https://static001.geekbang.org/infoq/e5/e5ffcb17cb56e867c9f6cf7d36a4cd69.png" alt="image"><br>其代码实现如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">processElement</span><span class="params">(StreamRecord&lt;Event&gt; element)</span> <span class="keyword">throws</span> Exception &#123;</span><br><span class="line">    <span class="type">Event</span> <span class="variable">event</span> <span class="operator">=</span> element.getValue();</span><br><span class="line">    <span class="keyword">if</span> (event <span class="keyword">instanceof</span> SchemaChangeEvent) &#123;</span><br><span class="line">        <span class="comment">// Update hash function</span></span><br><span class="line">        <span class="type">TableId</span> <span class="variable">tableId</span> <span class="operator">=</span> ((SchemaChangeEvent) event).tableId();</span><br><span class="line">        cachedHashFunctions.put(tableId, recreateHashFunction(tableId));</span><br><span class="line">        <span class="comment">// Broadcast SchemaChangeEvent</span></span><br><span class="line">        broadcastEvent(event);</span><br><span class="line">    &#125; <span class="keyword">else</span> <span class="keyword">if</span> (event <span class="keyword">instanceof</span> FlushEvent) &#123;</span><br><span class="line">        <span class="comment">// Broadcast FlushEvent</span></span><br><span class="line">        broadcastEvent(event);</span><br><span class="line">    &#125; <span class="keyword">else</span> <span class="keyword">if</span> (event <span class="keyword">instanceof</span> DataChangeEvent) &#123;</span><br><span class="line">        <span class="comment">// Partition DataChangeEvent by table ID and primary keys</span></span><br><span class="line">        partitionBy(((DataChangeEvent) event));</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="Sink"><a href="#Sink" class="headerlink" title="Sink"></a>Sink</h2><p>在 Sink 模块，需要将数据写出到外部系统中，并且将表结构变更应用到外部系统中。FlinkCDC 的 DataSink API 提供了 EventSinkProvider 和 MetaDataApplier 接口去完成这两件事情。</p>
<p><img src="https://static001.geekbang.org/infoq/60/60521b27755dfd35c7c47b17c2880c21.png" alt="image"></p>
<p>EventSinkProvider 用于将表数据变更应用到外部系统中。EventSinkProvider 要求提供一个基于 Flink SinkFunction 或者是 Flink Sink API 的实现，并且具备写出到多个表的能力。以 Flink Sink API 为例，SinkWriter 需要从 DataChangeEvent 中取出变更数据，并写出到对应的表中。当处理到 SchemaChangeEvent 时， SinkWriter 更新内存中保存的表结构信息。当处理到 FlushEvent 时， Sink Operator 会调用 SinkWriter 的 flush 方法将数据刷写出去。</p>
<p>MetaDataApplier 用于将表结构变更应用到外部系统中。在 SchemaRegistry 接受到所有的 Sink 算子处理完 FlushEvent 的通知后，由 SchemaRegistry 负责调用 MetaDataApplier 的 applySchemaChange 方法去应用表结构变更事件。考虑到任务重启的情况，MetaDataApplier 需要支持对一个表结构变更事件幂等处理。</p>
<p>该项目截止 2024年08月25日 ：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">    1632 text files.</span><br><span class="line">    1518 unique files.                                          </span><br><span class="line">     155 files ignored.</span><br><span class="line"></span><br><span class="line">github.com/AlDanial/cloc v 2.00  T=4.24 s (357.7 files/s, 62962.4 lines/s)</span><br><span class="line">-------------------------------------------------------------------------------</span><br><span class="line">Language                     files          blank        comment           code</span><br><span class="line">-------------------------------------------------------------------------------</span><br><span class="line">Java                          1157          24068          34869         155646</span><br><span class="line">Markdown                       100           3225           1568          20615</span><br><span class="line">Maven                           55            630           1001           6289</span><br><span class="line">SQL                             57            452           1033           3516</span><br><span class="line">CSS                              3              1             17           2272</span><br><span class="line">HTML                            50            206            249           1637</span><br><span class="line">JSON                             4              0              0           1591</span><br><span class="line">XML                             14            125            258           1417</span><br><span class="line">SVG                              2              2             16            896</span><br><span class="line">YAML                            23            172            600            854</span><br><span class="line">SCSS                             2            106             34            453</span><br><span class="line">Ruby                             6             87            119            413</span><br><span class="line">JavaScript                      13             47            235            332</span><br><span class="line">Bourne Shell                     8             88            192            214</span><br><span class="line">TOML                             4            184            579            178</span><br><span class="line">C                                1             18             28            133</span><br><span class="line">Scala                            8             41            138             69</span><br><span class="line">Properties                       7             16            112             55</span><br><span class="line">Dockerfile                       2              8             34             29</span><br><span class="line">Text                             2              2              0             16</span><br><span class="line">-------------------------------------------------------------------------------</span><br><span class="line">SUM:                          1518          29478          41082         196625</span><br><span class="line">-------------------------------------------------------------------------------</span><br></pre></td></tr></table></figure>


<hr>
<h1 id="参考："><a href="#参考：" class="headerlink" title="参考："></a>参考：</h1><ul>
<li><a target="_blank" rel="noopener" href="https://developer.aliyun.com/article/1399426">Flink CDC 3.0 正式发布，详细解读新一代实时数据集成框架</a></li>
<li><a target="_blank" rel="noopener" href="https://xie.infoq.cn/article/1b9c14d003b57c9fbb277a854">Flink CDC：基于 Apache Flink 的流式数据集成框架</a></li>
<li><a target="_blank" rel="noopener" href="https://xie.infoq.cn/article/66726d61bc51dcfcb181919d9">新一代实时数据集成框架 Flink CDC 3.0 —— 核心技术架构解析</a></li>
<li><a href="#flink-cdc-30-%E8%AE%BE%E8%AE%A1%E5%8A%A8%E6%9C%BA">DBLog: 一个通用的变更数据捕获框架</a></li>
</ul>

</article>

    <div class="pagenator post-pagenator">
    
    
        <a class="extend prev post-prev" href="../2024-08-25-flink_cdc%E6%A0%B8%E5%BF%83/">上一篇</a>
    

    
    <p>上次更新 2025-11-06</p>
    
    
        <a class="extend next post-next" href="../../../../23/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/2024-08-23-DBLog_%E8%AE%BA%E6%96%87/">下一篇</a>
    
    </div>


    </div>
    <div class="footer">
        <div class="container">
    <div class="social">
	<ul class="social-list">
		
			
				
				
				<li>
					<a href="mailto:2228598786@qq.com" title="email" target="_blank">
					<i class="fa fa-email"></i>
					</a>
				</li>
			
		
			
		
			
		
			
		
			
		
			
		
			
				
				<li>
					<a href="https://github.com/Benjmmi" title="github" target="_self">
					<i class="fa fa-github"></i>
					</a>
				</li>
			
		
			
		
			
		
			
		
			
		
			
		
			
		
	</ul>
</div>
    <div class="copyright">
        <span>
            
            
            
                © Benjmmi 2017 - 2025
            
        </span>
    </div>
    <div class="power">
        <span>
            Powered by <a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a> & <a target="_blank" rel="noopener" href="https://github.com/CaiChenghan/iLiKE">iLiKE Theme</a>
        </span>
    </div>
    <script src="https://cdn.bootcss.com/jquery/3.3.1/jquery.js"></script>
    <!--page counter part-->
<script>
function addCount (Counter) {
    url=$('.article-date').attr('href').trim();
    title = $('.article-title').text().trim();
    var query = new AV.Query(Counter);
    //use url as unique idnetfication
    query.equalTo("url",url);
    query.find({
        success: function(results) {
            if (results.length>0) {
                var counter=results[0];
                counter.fetchWhenSave(true); //get recent result
                counter.increment("time");
                counter.save();
            } else {
                var newcounter=new Counter();
                newcounter.set("title",title);
                newcounter.set("url",url);
                newcounter.set("time",1);
                newcounter.save(null,{
                    success: function(newcounter) {
                        //alert('New object created');
                    }, error: function(newcounter,error) {
                        alert('Failed to create');
                    }
                })
            }
        },
        error: function(error) {
            //find null is not a error
            alert('Error:'+error.code+" "+error.message);
        }
    });
}
$(function() {
    var Counter=AV.Object.extend("Counter");
    //only increse visit counting when intering a page
    if ($('.article-title').length == 1) {
       addCount(Counter);
    }
    var query=new AV.Query(Counter);
    query.descending("time");
    // the sum of popular posts
    query.limit(10); 
    query.find({
        success: function(results) {
                for(var i=0;i<results.length;i++) {
                    var counter=results[i];
                    title=counter.get("title");
                    url=counter.get("url");
                    time=counter.get("time");
                    // add to the popularlist widget
                    showcontent=title+" ("+time+")";
                    //notice the "" in href
                    $('.popularlist').append('<li><a href="'+url+'">'+showcontent+'</a></li>');
                }
            },
        error: function(error) {
            alert("Error:"+error.code+" "+error.message);
        }
    });
});
</script>
</div>

  <script src='https://unpkg.com/mermaid@11.12.1/dist/mermaid.min.js'></script>
  <script>
    if (window.mermaid) {
      mermaid.initialize({theme: 'forest'});
    }
  </script>
    </div>
</body>
</html>
