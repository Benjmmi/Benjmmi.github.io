---
title: Kubernetes
date: 2021-04-01 17:29:11
categories: 
	- [gRPC]
tags:
  - microservices
  - Kubernetes
  - k8s
author: Jony
---


# 机制了解


- Informer机制
- WorkerQueue机制

# Informer 机制

## 角色理解


![client-go-informer-source-code](https://cloudnative.to/blog/client-go-informer-source-code/01.jpg)


- Controller：Informer 的实施载体，可以创建 Reflector 及控制 processLoop。
- API Server：Kubernetes 网关系统，集群入口
  - Reflector：反射器，实现对 API Server 指定类型对象的监控（ListAndWatch）。
    把从API Server数据获取到的数据放到 `DeltaFIFO` 队列中，充当生产者角色
  - SharedInformer：从 `DeltaFIFIO` 队列中获取数据并分发数据，充当消费者角色
  - Indexer：Indexer 使用一个线程安全的数据存储来存储对象和他们的键值。
- DeltaFIFO：数据中转站，先进先出的缓存队列。存储 Watch API 返回的各种事件。
- WorkQueue：Informer 除了更新本地缓存之外，还要将数据同步给响应控制器，WorkQueue 就是为了
  数据同步的问题而产生的


`Kubernetes 中 Controller` 的理解：当用户通过工具发起创建 Pod 命令时，会把将要创建的 Pod 
对象的数据信息存储到 `Etcd` 中，如果数据对象只保存在 `Etcd` 中，而不去节点创建那么 目标
`Pod` 只是 `Etcd` 中的一条数据而已，并没有实际的价值（svc、pv 等皆是）。**那么 Controller
的作用就是监听指定数据对象的变化，并针对这些变化作出响应的响应。比如：新增 Pod，那么将会响应为
创建一个 `docker` 实例**

## Kubernetes 控制器的演化进程

Controller 有个非常重要的作用就是监控集群内资源的状态，将发现其余期望的状态不相符的时候就会
发起相对于的操作，使其对应的资源符合期望状态。简而言之 Controller 就是维护状态之间的平衡

这里的资源包括：Pod、Service、Deploym 等

### Controller V1

初始 Controller 通过 `控制循环` ，来调节系统周期性的操作，在 Kubernetes 中也叫`调谐循环`。
控制循环操作步骤：
1. 从 `API Server` 中统计所有属于该 `Deployment` 的 `Pod` ，也就是获取当前 `Deployment` 的
  实际状态。
2. 获取当前 `Deployment` 的 `Replicas` 字段，也就是期望状态。
3. 比较期望状态和实际状态，如果未达到期望状态那么久新增 `Pod` 实例，如果超过了就删除 `Pod` 

初始的 Controller 通过循环进行上面的操作，在此过程中会不断的访问 `API Server` 获取状态信息。
但是当 Controller 多了起来，那么 `API Server` 的访问量会呈指数型增加，压力会非常的大。
为了解决 `API Server` 的问题，解决方案就是 `Informer`

### Controller V2

`Informer` 的作用就是通过统一访问统一下发的方式解决 `API Server` 被过度访问造成资源浪费的
问题。`Informer` 替代 `Controller` 去访问 `API Server` , `Controller` 获取状态信息
就会直接访问 `Informer` 不再与 `API Server` 发生交互，包括操作资源伸缩同样也是与 `Informer`
进行交接。

`Informer` 首次访问 `API Server` 通过 `LIST API` 获取所有资源的最新状态，然后再通过 `Watch`
去监听**所有资源**的状态变化，整个过程叫 `ListAndWatch`。整个 `ListAndWatch` 的过程是在 `Informer`
下的一个组件 `Reflector`  来完成。

这里衍生出了另一个问题，虽然不需要频繁访问 `API Server` 了，但是 `Watch` 的方位是所有的资源信息。如果
集群非常大，那么 `Watch` 也会占用很多资源，且很多状态信息根本不关心。为了解决这个局部性问题 `Informer`
通过为每个 Controller 分配一个 `Reflector` 分别 `Watch` 各自的资源这样就不需要每次都 `Watch` 所有的资源。

但是出现了另一个问题就是重复劳动力的问题，例如：本质上 `Pod` 同时受到了 `Deployment` 和 `StatefulSet` 管理，不需要创建两个 `Reflector` 出现不必要的资源浪费，所以为了解决重复劳动力的问题就出现了 `SharedInformer`

### Controller V3

`SharedInformer` 可以理解为共享 `Informer` ，因为很多控制器可能管理的是一个资源信息，比如 `Deployment`
和 `StatefulSet` 管理的都是 `Pod` 资源信息，所以他们两个可以共享一个 `Informer` 即可。

关于 `SharedInformer` 细节性的问题：`SharedInformer` 无法同时给多个 `Controller` 提供信息，所以就
需要 `Controller` 自己排队和重试。为了 `Controller` 更好的排队和重试 `SharedInformer` 提供了一个 
`Delta FIFO Queue` ，每当资源信息有更新的时候 `Reflector` 就会收到事件通知，并将对应的事件放入到 
`Delta FIFO Queue` 中，同时 `SharedInformer` 会从 `Delta FIFO Queue` 将事件读取出来缓存到本地。
同时 `SharedInformer` 还要将 **事件信息** 同步给各个控制器，为了解决这个问题，`SharedInformer` 提供
了一个工作队列 `Workqueue`，一旦有资源被添加、修改或者删除，就会将相应的事件加入到 `Workqueue` 中。
所有的控制器排队对 `Workqueue` 读取，一旦某个控制返现这个事件与自己相关，那就会执行相应的操作。如果操作
失败就该将事件放回队列，等到下次排到自己再重试。如果操作成功，就将该事件从队列中删除。



# 北极星了解

关于 client-go， client-go 有多个 client 分别为：

- ClientSet：最常用的 client，可以在 `kuberntes` 目前的所有原生资源对应 client
- Dynamic Client：是一种动态的 `client` 能太浓是处理 kubernetes 所有的资源。
  并且它也不同于 clientset，dynamic client 返回的对象是一个 map[string]interface{}
  ，如果一个 `controller` 需要控制所有的 API，可以还是用 `dynamic client` ，目前被
  用在 `garbage collector` 和 `namespace controller`
- ResetClient：是 `clientset` 和 `dynamic client` 的基础，上面两个 `client` 本质上
  都是 `RESTClient` 它提供了一些 RESTful 的函数，如 `Get()`、`Put()`、`Post()`、
  `Delete()` 。有 Codec 提供序列化功能。

关于 Client 的使用场景：
如果 `Controller` 只是需要控制 `Kubernetes` 的原生资源，如 `Pod`、`Deployments` 那么
`ClientSet` 基本足够
如果需要使用 `CRD` 来扩展 `Kuberntes` 的 API ，那么就需要使用 `Dynamic Client` 或 `RESTClient`

## 北极星控制器主流程

`startPolarisController` 主要包括`NewPolarisController`和`PolarisController.Run`两部分。

NewPolarisController 主要构建`PolarisController`r结构体。

该部分主要处理了以下逻辑：

构建并运行事件处理器`eventBroadcaster`。

添加 `podInformer`、`serviceInformer`、`endpointsInformer`、`namespaceInformer`的`ResourceEventHandlerFuncs`，其中主要为AddFunc、UpdateFunc、DeleteFunc三类方法。
构造 `podInformer`、`serviceInformer` 的Lister函数和HasSynced函数。

`PolarisController.Run` 主要包含`WaitForCacheSync`、`syncService`和`syncNamespace`三部分。

`syncService` 

主要流程如下：

1. 通过`SplitMetaNamespaceKey`获取`namespace`和`deployment`对象的name。
2. 调用`Lister`的接口获取的`service`的对象。
3. 判断获取 `service` 对象是否失败
4. 获取成功
  1. 从 cache 中获取 service 信息失败
    1. 获取失败，那就判断当前 service 为首次创建
    2. 同步 k8s 的 namespace 和 service 到 注册中心
  2. 从 cache 中获取 service 信息成功
    1. 获取成功就判断 service 是否发生变化，如果发生变化就同步到注册中心
5. 获取失败
  1. 从 cache 中查找 `service` 信息
  2. 如果 cache 中也查找不到，说明这个 service 没有通不过到注册中心过，结束处理
  3. 如果 cache 中查找到了，说明注册中心还保留当前信息，那么就把删除信息同步到注册中心





