---
layout: post
title: "datax_阅读理解1"
keywords: ""
description: ""
tagline: ""
date: '2024-08-26 10:37:23'
category: linux
tags: linux
---
> {{ page.description }}

# 前言
开源 Datax 是数据集成比较常用的工具，满足一般中小公司的场景使用，通常数据库数据不会有几百TB的场景。

# 设计理念
为了解决异构数据源同步问题，DataX将复杂的网状的同步链路变成了星型数据链路，DataX作为中间传输载体负责连接各种数据源。当需要接入一个新的数据源的时候，只需要将此数据源对接到DataX，便能跟已有的数据源做到无缝数据同步。

# DataX 框架设计
![image](https://cloud.githubusercontent.com/assets/1067175/17879884/ec7e36f4-6927-11e6-8f5f-ffc43d6a468b.png)

DataX本身作为离线数据同步框架，采用Framework + plugin架构构建。将数据源读取和写入抽象成为Reader/Writer插件，纳入到整个同步框架中。
- Reader：Reader为数据采集模块，负责采集数据源的数据，将数据发送给Framework。
- Writer： Writer为数据写入模块，负责不断向Framework取数据，并将数据写入到目的端。
- Framework：Framework用于连接reader和writer，作为两者的数据传输通道，并处理缓冲，流控，并发，数据转换等核心技术问题。


#### 核心模块介绍
1. DataX完成单个数据同步的作业，我们称之为Job，DataX接受到一个Job之后，将启动一个进程来完成整个作业同步过程。DataX Job模块是单个作业的中枢管理节点，承担了数据清理、子任务切分(将单一作业计算转化为多个子Task)、TaskGroup管理等功能。
1. DataXJob启动后，会根据不同的源端切分策略，将Job切分成多个小的Task(子任务)，以便于并发执行。Task便是DataX作业的最小单元，每一个Task都会负责一部分数据的同步工作。
1. 切分多个Task之后，DataX Job会调用Scheduler模块，根据配置的并发数据量，将拆分成的Task重新组合，组装成TaskGroup(任务组)。每一个TaskGroup负责以一定的并发运行完毕分配好的所有Task，默认单个任务组的并发数量为5。
1. 每一个Task都由TaskGroup负责启动，Task启动后，会固定启动Reader—>Channel—>Writer的线程来完成任务同步工作。
1. DataX作业运行起来之后， Job监控并等待多个TaskGroup模块任务完成，等待所有TaskGroup任务完成后Job成功退出。否则，异常退出，进程退出值非0

### DataX调度流程：
举例来说，用户提交了一个DataX作业，并且配置了20个并发，目的是将一个100张分表的mysql数据同步到odps里面。 DataX的调度决策思路是：
1. DataXJob根据分库分表切分成了100个Task。
1. 根据20个并发，DataX计算共需要分配4个TaskGroup。
1. 4个TaskGroup平分切分好的100个Task，每一个TaskGroup负责以5个并发共计运行25个Task。

DataX 对 Reader 和 Writer 做了抽象封装，新的数据源开发只需要实现这两个模块就可以。所以DataX核心实现逻辑为：同步的共性问题，比如：类型转换、性能、统计，则交由框架来处理。

# 二、插件视角看框架
## 逻辑执行模型
插件开发者不用关心太多，基本只需要关注特定系统读和写，以及自己的代码在逻辑上是怎样被执行的，哪一个方法是在什么时候被调用的。在此之前，需要明确以下概念：

- Job: Job是DataX用以描述从一个源头到一个目的端的同步作业，是DataX数据同步的最小业务单元。比如：从一张mysql的表同步到odps的一个表的特定分区。
- Task: Task是为最大化而把Job拆分得到的最小执行单元。比如：读一张有1024个分表的mysql分库分表的Job，拆分成1024个读Task，用若干个并发执行。
- TaskGroup: 描述的是一组Task集合。在同一个TaskGroupContainer执行下的Task集合称之为TaskGroup
- JobContainer: Job执行器，负责Job全局拆分、调度、前置语句和后置语句等工作的工作单元。类似Yarn中的JobTracker
- TaskGroupContainer: TaskGroup执行器，负责执行一组Task的工作单元，类似Yarn中的TaskTracker。
简而言之， Job拆分成Task，在分别在框架提供的容器中执行，插件只需要实现Job和Task两部分逻辑。


看着有点像 Flink 的 JobManager、JobGraph。

# 编程接口

```java
public class Some(Reader|Writer) extends Reader {
    public static class Job extends Reader.Job {
        /**
         * init: Job对象初始化工作，此时可以通过super.getPluginJobConf()获取与本插件相关的配置。
         * 读插件获得配置中reader部分，写插件获得writer部分。
         */
        @Override
        public void init() {}

        /**
         * 全局准备工作，比如odpswriter清空目标表。
         */
        @Override
        public void prepare() {}

        /**
         * 拆分Task。参数adviceNumber框架建议的拆分数，一般是运行时所配置的并发度。值返回的是Task的配置列表。
         *
         * @param adviceNumber
         *
         *            着重说明下，adviceNumber是框架建议插件切分的任务数，插件开发人员最好切分出来的任务数>=
         *            adviceNumber。<br>
         * <br>
         *            之所以采取这个建议是为了给用户最好的实现，例如框架根据计算认为用户数据存储可以支持100个并发连接，
         *            并且用户认为需要100个并发。 此时，插件开发人员如果能够根据上述切分规则进行切分并做到>=100连接信息，
         *            DataX就可以同时启动100个Channel，这样给用户最好的吞吐量 <br>
         *            例如用户同步一张Mysql单表，但是认为可以到10并发吞吐量，插件开发人员最好对该表进行切分，比如使用主键范围切分，
         *            并且如果最终切分任务数到>=10，我们就可以提供给用户最大的吞吐量。 <br>
         * <br>
         *            当然，我们这里只是提供一个建议值，Reader插件可以按照自己规则切分。但是我们更建议按照框架提供的建议值来切分。 <br>
         * <br>
         *            对于ODPS写入OTS而言，如果存在预排序预切分问题，这样就可能只能按照分区信息切分，无法更细粒度切分，
         *            这类情况只能按照源头物理信息切分规则切分。 <br>
         * <br>
         *
         *
         * @return
         */
        @Override
        public List<Configuration> split(int adviceNumber) { return null;}

        /**
         * 全局的后置工作，比如mysqlwriter同步完影子表后的rename操作。
         */
        @Override
        public void post() {}

        /**
         * Job对象自身的销毁工作。
         */
        @Override
        public void destroy() {}
    }
    public static class Task extends (Reader|Writer).Task {

        /**
         * Task对象的初始化。此时可以通过super.getPluginJobConf()获取与本Task相关的配置。这里的配置是Job的split方法返回的配置列表中的其中一个。
         */
        @Override
        public void init() {}

        /**
         * 局部的准备工作。
         */
        @Override
        public void prepare() {}

        /**
         * 从数据源读数据，写入到RecordSender中。RecordSender会把数据写入连接Reader和Writer的缓存队列。
         * @param recordSender
         */
        @Override
        public void startRead(RecordSender recordSender) {}

        /**
         * 从RecordReceiver中读取数据，写入目标数据源。
         * RecordReceiver中的数据来自Reader和Writer之间的缓存队列。
         */
        @Override
        public void startWrite(RecordReceiver lineReceiver) {}

        /**
         * 局部的后置工作。
         */
        @Override
        public void post() {}

        /**
         * Task象自身的销毁工作。
         */
        @Override
        public void destroy() {}
    }
}
```

***NOTE***
- Job和Task之间一定不能有共享变量，因为分布式运行时不能保证共享变量会被正确初始化。两者之间只能通过配置文件进行依赖。
- prepare和post在Job和Task中都存在，插件需要根据实际情况确定在什么地方执行操作。
![image](https://github.com/alibaba/DataX/blob/master/images/plugin_dev_guide_1.png)



---
参考：
- [DataX源码解析](https://tyrantlucifer.com/datax-02.html){:target='blank'}
