---
layout: post
title: "flink_cdc_概念拆解"
keywords: ""
description: ""
tagline: ""
date: '2024-08-25 12:35:50 +0800'
category: linux
tags: linux
---
> {{ page.description }}
# 动机
对目前所做工作的进一步演化，行业内知识对标
# 拆解来源
[Flink CDC 3.0 正式发布，详细解读新一代实时数据集成框架](https://developer.aliyun.com/article/1399426)

# Flink CDC 概述
Flink CDC 是基于数据库日志 CDC（Change Data Capture）技术的实时数据集成框架，支持了全增量一体化、无锁读取、并行读取、表结构变更自动同步、分布式架构等高级特性。

# Flink CDC 3.0 设计动机
- 历史数据规模大：数据库的历史数据规模大，100T+ 规模很常见
- 增量数据实时性要求高：数据库的增量数据业务价值高，且价值随时间递减，需要实时处理
- 数据的保序性：CDC 数据的加工结果通常需要强一致性语义，需要处理工具支持全局保序
- 表结构动态变化：增量数据随时间增长，数据对应的表结构会不断演进

目标
- 端到端体验：Flink CDC 3.0 定位为端到端的数据集成框架，API 设计直接面向数据集成场景，帮助用户轻松构建同步作业
- 自动化：上游 schema 变更自动同步到下游，已有作业支持动态加表
- 极致扩展：空闲资源自动回收，一个 sink 实例支持写入多表
- 

该项目截止 2024年08月25日 ：
```bash
    1632 text files.
    1518 unique files.                                          
     155 files ignored.

github.com/AlDanial/cloc v 2.00  T=4.24 s (357.7 files/s, 62962.4 lines/s)
-------------------------------------------------------------------------------
Language                     files          blank        comment           code
-------------------------------------------------------------------------------
Java                          1157          24068          34869         155646
Markdown                       100           3225           1568          20615
Maven                           55            630           1001           6289
SQL                             57            452           1033           3516
CSS                              3              1             17           2272
HTML                            50            206            249           1637
JSON                             4              0              0           1591
XML                             14            125            258           1417
SVG                              2              2             16            896
YAML                            23            172            600            854
SCSS                             2            106             34            453
Ruby                             6             87            119            413
JavaScript                      13             47            235            332
Bourne Shell                     8             88            192            214
TOML                             4            184            579            178
C                                1             18             28            133
Scala                            8             41            138             69
Properties                       7             16            112             55
Dockerfile                       2              8             34             29
Text                             2              2              0             16
-------------------------------------------------------------------------------
SUM:                          1518          29478          41082         196625
-------------------------------------------------------------------------------
```
# 架构
Flink CDC 3.0 的整体架构自顶而下分为 4 层：
- **Flink CDC AP**I：面向终端用户的 API 层，用户使用 YAML 格式配置数据同步流水线，使用 Flink CDC CLI 提交任务
- **Flink CDC Connect**：对接外部系统的连接器层，通过对 Flink 与现有 Flink CDC source 进行封装实现对外部系统同步数据的读取和写入
- **Flink CDC Composer**：同步任务的构建层，将用户的同步任务翻译为 Flink DataStream 作业
- **Flink CDC Runtime**：运行时层，根据数据同步场景高度定制 Flink 算子，实现 `schema` 变更、路由、变换等高级功能
![图片](https://ucc.alicdn.com/gfbp4bwpctdbo_20231219_ae636f33d7f041f79e245dc9d077c197.png?x-oss-process=image/resize,w_1400/format,webp)
分别对应项目 
```bash
/fink-cdc
---/flink-cdc-cli
---/flink-cdc-composer
---/flink-cdc-connect
---/flink-cdc-runtime
```

1. Flink CDC 3.0 的用户 API 设计专注于数据集成场景，用户无需关注框架实现，只需使用 YAML 格式描述数据来源与目标端即可快速构建一个数据同步任务。

2. 为了更好地将外部系统对接至 Flink CDC 3.0 的数据同步流水线，Flink CDC 3.0 定义了 `Pipeline Connector` API
    - **DataSource**：Flink CDC 3.0 的数据源，由负责构建 Flink Source 的 `EventSourceProvider` 和提供元信息读取能力的 MetadataAccessor 组成。DataSource 从外部系统中读取变更事件 Event，并传递给下游算子。
    - **DataSink**：Flink CDC 3.0 的数据目标端，由负责构建 Flink Sink 的 `EventSinkProvider` 和提供对目标端元信息修改能力的 `MetadataApplier` 构成。DataSink 将上游算子传递来的变更事件 `Event` 写出至外部系统，`MetadataApplier` 负责处理上游的 `schema` 变更信息并应用至外部系统，实现 schema 变更的实时处理。

3. `Schema` 变更处理是上游数据库中十分常见的用户场景，也是数据同步框架实现的难点。针对该场景，Flink CDC 3.0 在作业拓扑中引入了 `SchemaRegistry`，结合 `SchemaOperator` 协调并控制作业拓扑中的 `schema` 变更事件处理。当上游数据源发生 `schema` 变更时，SchemaRegistry 会控制 `SchemaOperator` 以暂停数据流，并将流水线中的数据从 sink 全部刷出以保证 `schema` 一致性。当 `schema` 变更事件在外部系统处理成功后，`SchemaOperator` 恢复数据流，完成本次 `schema` 变更的处理。

![image](https://ucc.alicdn.com/gfbp4bwpctdbo_20231219_0c124ba82fae4da4a6e84aa6dc98ea3b.png?x-oss-process=image/resize,w_1400/format,webp)


# 整库同步设计
用户可以在 Flink CDC 3.0 的配置文件中指定 `DataSource` 同步任务捕获上游多表或整库变更，结合 `Schema Evolution` 的设计，`SchemaRegistry` 会在读取到新表的数据后，自动在目标端外部系统建表，实现自动化的数据整库同步。
![image](https://ucc.alicdn.com/gfbp4bwpctdbo_20231219_15982fc9f6f94f7e9260b91bd6f35485.png?x-oss-process=image/resize,w_1400/format,webp)

# 分库分表同步设计
在数据同步中，一个常见的使用场景是将上游由于业务或数据库性能问题而拆分的多表在下游系统合并为一张表。Flink CDC 3.0 使用路由（`Route`）机制实现分库分表合并的能力。用户可以在配置文件中定义 `Route` 规则使用正则表达式匹配多张上游表，并将其指向同一张目标表，实现分库分表数据的归并。

![image](https://ucc.alicdn.com/gfbp4bwpctdbo_20231219_f94f3898baba442da66f2947db67727a.png?x-oss-process=image/resize,w_1400/format,webp)

# 拆解

数据源使用 `EventSourceProvider` 数据接收器使用 `EventSinkProvider` ,元数据变更接收器 `MetadataApplier`。

>> `Schema` 变更处理数据处理，是作业拓扑中引入了 `SchemaRegistry`，结合 `SchemaOperator` 协调并控制作业拓扑中的 schema 变更事件处理。
这个操作的具体实现方式:

>> 整个库同步使用结合 `Schema Evolution` 的设计，`SchemaRegistry`

>> 分库分表同步使用 `Route` 规则使用正则表达式匹配多张上游表


---
参考：
- [](){:target='blank'}
- [](){:target='blank'}
